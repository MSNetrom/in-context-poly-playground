function_class: 
    type: chebyshev kernel linear regression
    lowest_degree: 0
    highest_degree: 5
    fixed_linear_coefficients: 2
    different_degrees: False
steps: 100000
log_freq: 2000
checkpoint_freq: 20000
optim:
    type: adam
    lr: 0.00005
loss_fn:
    type: mse
b_size: 64
seq_len: 31
x_dim: 1
x_dist:
    type: uniform
model: 
    <<: *lora_std_gpt2
    lora_config:
        r: 4
        lora_alpha: 16
        bias: none
        fan_in_fan_out: True
        lora_dropout: 0.0
        target_modules: ["attn.c_attn"]